# 跨数据库（数据源）迁移

yugong

去Oracle数据迁移同步工具。定位：数据库迁移（目前主要支持Oracle-&gt;mysql/DRDS）



08年左右，阿里巴巴开始尝试MySQL的相关研究，并开发了基于MySQL分库分表技术的相关产品，Cobar/TDDL\(目前为阿里云DRDS产品\)，解决了单机Oracle无法满足的扩展性问题，当时也掀起一股去IOE项目的浪潮，愚公这项目因此而诞生，其要解决的目标就是帮助用户完成从Oracle数据迁移到MySQL上，完成去IOE的第一步.



概述

整个数据迁移过程，分为两个部分：



全量迁移



增量迁移







过程描述：



增量数据收集（创建Oracle表的增量物化视图）



进行全量复制



进行增量复制（可并行进行数据校验）



原库停写，切换到新库



Oracle全量基于JDBC拉取数据，增量基于物化视图来实现。



架构





说明：



一个JVM Container 对应多个instance，每个instance对应于一张表的迁移任务



instance分为三部分



extractor \(从数据源库上提取数据，可分为全量/增量实现\)



translator （将源库上的数据按照目标库的需求进行自定义转化）



applier（将数据更新到目标库，可分为全量/增量/对比的实现）



自定义数据转换

如果要迁移的Oracle和mysql的表结构不同，比如表名，字段名有差异，字段类型不兼容，需要使用自定义数据转换。如果完全相同则可以跳过。



整个数据流为：DB-&gt;Extractor-&gt;DataTranslator-&gt;Applier-&gt;DB, 本程序预留DataTranslator接口（仅支持Java），允许外部用户自定义数据处理逻辑。比如：



表名不同



字段名不同



字段类型不同



字段个数不同



运行过程join其他表的数据做计算等



运行模式介绍

1.MARK模式（MARK）



开启增量日志模式，如果是Oracle就是创建物化视图（materialized view）。



2.CLEAR模式（CLEAR）



清理增量日志的几率，如果是Oracle就是删除物化视图



3.全量模式（FULL\)



全量模式，顾名思议即为对源表进行一次全量操作，遍历源表所有的数据后，插入目标表.



全量有两种处理方式：



分页处理：如果源表存在主键，只有一个主键字段，并且主键字段类型为Number类型，默认会选择该分页处理模式. 优点：支持断点续做，对源库压力相对较小。 缺点：迁移速度慢



once处理：通过select \* from访问整个源表的某一个mvcc版本的数据，通过cursor.next遍历整个结果集. 优点：迁移速度快，为分页处理的5倍左右。 缺点：源库压力大，如果源库并发修改量大，会导致数据库MVCC版本过多，出现栈错误. 还有就是不支持断点续做.



4.增量模式（INC）



全量模式，顾名思议即为对源表增量变化的数据插入目标表，增量模式依赖记录日志功能.



目前增量模式的记录日志功能，是通过oracle的物化视图功能。



5.自动模式\(ALL\)



自动模式，是对全量+增量模式的一种组合，自动化运行，减少操作成本.



自动模式的内部实现步骤：



开启记录日志功能. \(创建物化视图\)



运行全量同步模式. \(全量完成后，自动进入下一步\)



运行增量同步模式. \(增量模式，没有完成的概念，所以也就不会自动退出，需要业务判断是否可以退出，可以看一下切换流程\)



6.对比模式\(CHECK\)



对比模式，即为对源库和目标库的数据进行一次全量对比，验证一下迁移结果. 对比模式为一种可选运行，做完全量/增量/自动模式后，可选择性的运行对比模式，来确保本次迁移的正确性.



DataX

DataX是一个在异构的数据库/文件系统之间高速交换数据的工具，实现了在任意的数据处理系统\(RDBMS/Hdfs/Local filesystem）之间的数据交换。



目前成熟的数据导入导出工具比较多，但是一般都只能用于数据导入或者导出，并且只能支持一个或者几个特定类型的数据库。



这样带来的一个问题是，如果我们拥有很多不同类型的数据库/文件系统\(Mysql/Oracle/Rac/Hive/Other…\)，并且经常需要在它们之间导入导出数据，那么我们可能需要开发/维护/学习使用一批这样的工具\(jdbcdump/dbloader/multithread/getmerge+sqlloader/mysqldumper…\)。而且以后每增加一种库类型，我们需要的工具数目将线性增长。\(当我们需要将mysql的数据导入oracle的时候，有没有过想从jdbcdump和dbloader上各掰下来一半拼在一起到冲动？\)这些工具有些使用文件中转数据，有些使用管道，不同程度的为数据中转带来额外开销，效率差别很非常大。很多工具也无法满足ETL任务中常见的需求，比如日期格式转化，特性字符的转化，编码转换。另外，有些时候，我们希望在一个很短的时间窗口内，将一份数据从一个数据库同时导出到多个不同类型的数据库。DataX正是为了解决这些问题而生。







左图：新增第n+1个数据源，是不是需要开发n个数据同步工具？



右图：只需要针对新增的数据源开发一套Reader/Writer插件，即可实现任意数据的互导。



设计理念

为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。



DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。



框架设计





DataX本身作为离线数据同步框架，采用Framework+plugin架构构建。将数据源读取和写入抽象称为Reader/Writer插件，纳入到整个同步框架中。



Reader： Reader为数据采集模块，负责采集数据源的数据，将数据发送给Framework.



Writer：Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端



Framework：Framework用于连接reader和writer,作为两者的数据传输通道，并处理缓存，流控，并发，数据转换等核心技术问题。



DataX框架内部通过双缓冲队列、线程池封装等技术，集中处理了高速数据交换遇到的问题，提供简单的接口与插件交互，插件分为Reader和Writer两类，基于框架提供的插件接口，可以十分便捷的开发出需要的插件。比如想要从oracle导出数据到mysql，那么需要做的就是开发出OracleReader和MysqlWriter插件，装配到框架上即可。并且这样的插件一般情况下在其他数据交换场合是可以通用的。



核心架构

DataX3.0 开源版本支持单机多线程模式完成同步作业运行，这里按一个DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。







核心模块介绍：



DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分\(将单一作业计算转化为多个子Task\)、TaskGroup管理等功能。



DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task\(子任务\)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。



切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup\(任务组\)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。



每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—&gt;Channel—&gt;Writer的线程来完成任务同步工作。



DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0。



DataX调度流程：



举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。 DataX的调度决策思路是：

1. DataXJob根据分库分表切分成了100个Task。

2. 根据20个并发，DataX计算共需要分配4个TaskGroup。

3. 4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。

